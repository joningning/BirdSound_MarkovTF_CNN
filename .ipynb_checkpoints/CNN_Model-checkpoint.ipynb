{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b5fbe0-c5e6-4551-8a99-9ff558e13bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8659578-d5cb-48ca-8047-d8c292f6ff58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/mtf_data_set\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path\n",
    "# data_dir = tf.keras.preprocessing.image_dataset_from_directory(\"./dataset/data_sets/Passer montanus_Eurasian Tree Sparrow/EurasianTreeSparrow_MTFimage\")\n",
    "data_dir = \"./dataset/mtf_data_set\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2c42074-aa9b-434c-a63b-21b76dec5065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 files.\n",
      "Using 60 files for training.\n",
      "<_PrefetchDataset element_spec=TensorSpec(shape=(None, 400, 1000, 3), dtype=tf.float32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 1000, 400\n",
    "batch_size = 25\n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#   data_dir,\n",
    "#   validation_split=0.2,\n",
    "#   subset=\"training\",\n",
    "#   seed=123,\n",
    "#   image_size=(img_height, img_width),\n",
    "#   batch_size=batch_size)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels=None,\n",
    "    # label_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    # shuffle=True,\n",
    "    subset='training',\n",
    "    seed=100,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7aa131f-88de-4ff7-9ff7-ab5570ee8de7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (train_images, train_labels, test_images, test_labels) \u001b[38;5;241m=\u001b[39m train_ds\n\u001b[0;32m      2\u001b[0m train_images, test_images \u001b[38;5;241m=\u001b[39m train_images \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m, test_images \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels, test_images, test_labels) = train_ds\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f2e88-9116-49d2-835c-0127e5e491fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(400, 1000, 2)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(8, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62cdd1-add8-47e3-9781-cb957a51a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971e80c-44bd-4bf7-a83e-07f8f5cf9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1756b3-8d43-4f14-8cfd-a1abec3de19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
